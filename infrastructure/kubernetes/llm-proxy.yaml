apiVersion: apps/v1
kind: Deployment
metadata:
  name: llm-proxy
  namespace: falcon-kaito
spec:
  replicas: 1
  selector:
    matchLabels:
      app: llm-proxy
  template:
    metadata:
      labels:
        app: llm-proxy
    spec:
      containers:
      - name: nginx
        image: nginx:stable-alpine
        ports:
        - containerPort: 80
        volumeMounts:
        - name: nginx-config
          mountPath: /etc/nginx/conf.d
      volumes:
      - name: nginx-config
        configMap:
          name: llm-proxy-config

---
apiVersion: v1
kind: ConfigMap
metadata:
  name: llm-proxy-config
  namespace: falcon-kaito
data:
  default.conf: |
    server {
      listen 80;

      location / {
        # Add CORS headers
        add_header 'Access-Control-Allow-Origin' '*';
        add_header 'Access-Control-Allow-Methods' 'GET, POST, OPTIONS';
        add_header 'Access-Control-Allow-Headers' 'Content-Type, Authorization';

        # Handle preflight requests
        if ($request_method = OPTIONS) {
          return 204;
        }

        proxy_pass http://workspace-falcon-7b-inference-adapter.falcon-kaito.svc.cluster.local:80;
      }
    }
---
apiVersion: v1
kind: Service
metadata:
  name: llm-proxy-service
  namespace: falcon-kaito
spec:
  type: LoadBalancer
  ports:
  - port: 80
    targetPort: 80
  selector:
    app: llm-proxy